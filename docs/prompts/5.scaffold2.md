Quick take:

- **Yes:** make a small **infra “mono-repo”** for Hephaestus (compose, Caddyfile, Grafana/Prometheus, Cloudflared, docs).
    
- **Apps:** keep each **app in its own repo** (what you deploy elsewhere today). In the homelab tree, just clone them into the scaffold folders you already made.
    

### Why this split?

- **Infra repo (hephaestus-homelab):** single place to boot, update, and back up the platform. No app secrets/code here.
    
- **App repos:** keep CI/CD, issues, and histories clean and portable (cloud ↔ homelab).
    

Suggested layout:

```
hephaestus-homelab/            # git repo (infra only)
  docker-compose.yml
  proxy/Caddyfile
  grafana-stack/{docker-compose.yml,prometheus.yml}
  .env.example
  docs/

~/homelab/                     # working dir on the box (not all tracked)
  magic-pages/                 # (cloned app repo)
  portfolio/                   # (cloned app repo)
  schedshare/                  # (cloned app repo)
  capitolscope/                # (cloned app repo)
  magicpages-frontend/         # (static/build artifacts; optional own repo)
```

`.gitignore` (infra repo):

```
.env
**/*.env
**/data/**
**/site/**
**/__pycache__/**
```

---

## Starters you asked for

Below are minimal, production-ish entry files matching the compose you have. Drop them into the paths noted (or replace with your real apps later).

### 1) Portfolio (Flask) — `~/homelab/portfolio/app/app.py`

```python
from flask import Flask, jsonify

app = Flask(__name__)

@app.get("/")
def index():
    return "<h1>Chris Lawrence — Portfolio</h1><p>Served by Hephaestus.</p>"

@app.get("/health")
def health():
    return jsonify(status="ok"), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
```

### 2) SchedShare (Flask) — `~/homelab/schedshare/app/app.py`

```python
from flask import Flask, jsonify, request

app = Flask(__name__)

@app.get("/")
def home():
    return "<h1>SchedShare</h1><p>Parsing schedules…</p>"

@app.get("/health")
def health():
    # add dependency checks here if needed
    return jsonify(status="ok"), 200

# example API stub
@app.post("/parse")
def parse():
    payload = request.get_json(silent=True) or {}
    return jsonify(received=payload, message="Stub parser"), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
```

### 3) CapitolScope (FastAPI) — `~/homelab/capitolscope/app/main.py`

```python
from fastapi import FastAPI
from pydantic import BaseModel
import os

app = FastAPI(title="CapitolScope")

@app.get("/")
def root():
    return {"app": "CapitolScope", "msg": "Tracking congressional trades"}

@app.get("/health")
def health():
    # e.g., verify DB URL present
    ok = bool(os.getenv("DATABASE_URL"))
    return {"status": "ok" if ok else "degraded"}

class TickerIn(BaseModel):
    symbol: str

@app.post("/api/track")
def track(t: TickerIn):
    # stub; replace with real logic
    return {"tracking": t.symbol.upper()}
```

### 4) Magic Pages API (Django + Gunicorn)

For Django you don’t use `app.py`; you serve a **WSGI** app. Quick bootstrap:

```bash
cd ~/homelab/magic-pages/app
python -m django --version || pip install Django
django-admin startproject app .          # creates manage.py, app/settings.py, app/wsgi.py
```

Edit **`~/homelab/magic-pages/app/app/settings.py`** (minimal changes):

```python
import os, dj_database_url
from pathlib import Path
BASE_DIR = Path(__file__).resolve().parent.parent

SECRET_KEY = os.getenv("DJANGO_SECRET_KEY", "dev-not-secure")
DEBUG = os.getenv("DJANGO_DEBUG", "False") == "True"
ALLOWED_HOSTS = ["*"]

INSTALLED_APPS = [
    "django.contrib.contenttypes",
    "django.contrib.staticfiles",
]

MIDDLEWARE = []
ROOT_URLCONF = "app.urls"
WSGI_APPLICATION = "app.wsgi.application"

DATABASES = {
    "default": dj_database_url.config(default=os.getenv("DATABASE_URL", "sqlite:///db.sqlite3"))
}

STATIC_URL = "static/"
STATIC_ROOT = BASE_DIR / "staticfiles"
```

Create **`~/homelab/magic-pages/app/app/urls.py`**:

```python
from django.urls import path
from django.http import JsonResponse, HttpResponse

def index(_):
    return HttpResponse("<h1>Magic Pages API</h1><p>Hephaestus Django stub.</p>")

def health(_):
    return JsonResponse({"status": "ok"})

urlpatterns = [
    path("", index),
    path("health", health),
]
```

(**`app/wsgi.py`** is generated by Django and already matches the Gunicorn command in your compose.)

With your `.env.magicpages` set, this will run and expose `/health`.

---

## Grafana dashboard (import-ready JSON)

This is a compact, useful starter that expects:

- **node_exporter** at `127.0.0.1:9100`
    
- **cAdvisor** at `cadvisor:8080`
    
- **Uptime Kuma** metrics enabled (Settings → Prometheus) at `uptime-kuma:3001`
    

Save as `~/homelab/grafana-stack/hephaestus-overview.json`, then in Grafana: _Dashboards → New → Import → Upload JSON_.

```json
{
  "title": "Hephaestus Overview",
  "uid": "hephaestus-overview",
  "timezone": "browser",
  "schemaVersion": 38,
  "version": 1,
  "refresh": "10s",
  "panels": [
    {
      "type": "stat",
      "title": "CPU Usage (%)",
      "gridPos": { "x": 0, "y": 0, "w": 6, "h": 4 },
      "targets": [
        {
          "expr": "100 - (avg by (instance)(rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
          "refId": "A"
        }
      ]
    },
    {
      "type": "stat",
      "title": "Memory Used (%)",
      "gridPos": { "x": 6, "y": 0, "w": 6, "h": 4 },
      "targets": [
        {
          "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
          "refId": "A"
        }
      ]
    },
    {
      "type": "graph",
      "title": "Disk IO (bytes/sec)",
      "gridPos": { "x": 12, "y": 0, "w": 12, "h": 8 },
      "targets": [
        { "expr": "rate(node_disk_read_bytes_total[5m])", "legendFormat": "{{device}} read", "refId": "A" },
        { "expr": "rate(node_disk_written_bytes_total[5m])", "legendFormat": "{{device}} write", "refId": "B" }
      ]
    },
    {
      "type": "graph",
      "title": "Network (bytes/sec)",
      "gridPos": { "x": 0, "y": 4, "w": 12, "h": 8 },
      "targets": [
        { "expr": "sum(rate(node_network_receive_bytes_total{device!~\"lo|docker.*\"}[5m]))", "legendFormat": "RX", "refId": "A" },
        { "expr": "sum(rate(node_network_transmit_bytes_total{device!~\"lo|docker.*\"}[5m]))", "legendFormat": "TX", "refId": "B" }
      ]
    },
    {
      "type": "table",
      "title": "Top Containers by CPU",
      "gridPos": { "x": 12, "y": 8, "w": 12, "h": 8 },
      "options": { "showHeader": true },
      "targets": [
        {
          "expr": "sum(rate(container_cpu_usage_seconds_total{image!=\"\",name!~\".*(pause|POD).*\"}[5m])) by (name)",
          "refId": "A",
          "format": "table"
        }
      ]
    },
    {
      "type": "table",
      "title": "Top Containers by Memory (MB)",
      "gridPos": { "x": 0, "y": 12, "w": 12, "h": 8 },
      "options": { "showHeader": true },
      "targets": [
        {
          "expr": "sort_desc(sum(container_memory_working_set_bytes{image!=\"\",name!~\".*(pause|POD).*\"}) by (name))",
          "refId": "A",
          "format": "table"
        }
      ],
      "transformations": [
        { "id": "organize", "options": { "excludeByName": {}, "indexByName": {}, "renameByName": { "Value": "bytes" } } },
        { "id": "calculateField", "options": { "mode": "binary", "binary": { "reducer": "last", "left": "bytes", "operator": "/", "right": "1048576" }, "alias": "MB" } }
      ]
    },
    {
      "type": "stat",
      "title": "Kuma Monitors Up",
      "gridPos": { "x": 0, "y": 20, "w": 6, "h": 4 },
      "targets": [
        { "expr": "sum(uptimekuma_up)", "refId": "A" }
      ]
    },
    {
      "type": "stat",
      "title": "Kuma Monitors Down",
      "gridPos": { "x": 6, "y": 20, "w": 6, "h": 4 },
      "targets": [
        { "expr": "sum(uptimekuma_up == 0)", "refId": "A" }
      ]
    }
  ],
  "templating": { "list": [] }
}
```

> If any panel shows “No data”, confirm Prometheus targets are up: Prometheus → _Status → Targets_.

---

## Next steps

1. Create the **infra repo** and commit your compose/Caddy/Grafana config (no secrets).
    
2. Drop the starters above into each app folder (or clone your real repos there).
    
3. `docker compose build && docker compose up -d`
    
4. Import the Grafana dashboard JSON.
    
5. Add Caddy routes for each hostname you want public and wire them via Cloudflare Tunnel.
    

If you want, I can also generate **`requirements.txt`** stubs for each Python app with common libs you’ll likely need (Flask/Requests/Cors/FastAPI/SQLAlchemy, etc.) or tailor them to your real repos.